import os
import requests

OLLAMA_URL = os.getenv("OLLAMA_URL", "http://localhost:11434")

def query_ollama(prompt: str, model="mistral"):
    response = requests.post(
        f"{OLLAMA_URL}/api/generate",
        json={
            "model": model,
            "prompt": prompt,
            "stream": False,
            "options": {
                "temperature": 0.7,
                "top_p": 0.9,
                "num_ctx": 4096  # Increase context window
            }
        }
    )

    if response.status_code != 200:
        print("‚ùå Erro ao comunicar com o Ollama:", response.text)
        return "Erro ao gerar resposta."

    json_data = response.json()

    if "response" not in json_data:
        print("‚ö†Ô∏è Resposta inesperada do Ollama:", json_data)
        return "N√£o foi poss√≠vel obter uma resposta do modelo."

    return json_data["response"]


def test_ollama_connection():
    """Testa a conex√£o com o Ollama e lista modelos dispon√≠veis."""
    try:
        # Verifica se o Ollama est√° rodando
        response = requests.get(f"{OLLAMA_URL}/api/tags")
        if response.status_code == 200:
            models = response.json().get("models", [])
            print("üü¢ Ollama conectado. Modelos dispon√≠veis:")
            for model in models:
                print(f"  - {model['name']}")
            return True
        else:
            print("‚ùå Ollama n√£o est√° respondendo corretamente")
            return False
    except requests.exceptions.ConnectionError:
        print("‚ùå N√£o foi poss√≠vel conectar ao Ollama")
        return False


if __name__ == "__main__":
    # Teste de conex√£o
    if test_ollama_connection():
        # Teste simples de gera√ß√£o
        test_response = query_ollama("Responde em portugu√™s: Qual √© a capital do Brasil?")
        print(f"\nüß™ Teste de resposta:\n{test_response}")